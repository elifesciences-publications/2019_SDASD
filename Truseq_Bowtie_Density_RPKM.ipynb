{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "### requirement\n",
    "# bowtie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastq_path = '^fastq/'\n",
    "filepath = '^resuts/'\n",
    "files = ['ks68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for bowtie\n",
    "inpath = fastq_path\n",
    "outpath = filepath\n",
    "bowtie_input_extension = '.fastq'\n",
    "bowtie_logfile = inpath+'log_bowtie.txt'\n",
    "\n",
    "# for mapping\n",
    "mapping = '_5map_OS'\n",
    "\n",
    "# for RPKM\n",
    "gene_type = '_gene'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2019-08-01 12:04:48.532896\n",
      "\n",
      "\n",
      "ks68\n",
      "bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 --un ^resuts/alignments/ladder/ks68_nomatch.fastq --max ^resuts/alignments/ladder/ks68_multi.fastq --al ^resuts/alignments/ladder/ks68_match.fastq ^index/ladder/ladder ^fastq/ks68.fastq ^resuts/tmpds/ks68_ladder_match.SAM 1>> ^fastq/log_bowtie.txt 2>> ^fastq/log_bowtie.txt\n",
      "# reads processed: 49964939\n",
      "# reads with at least one reported alignment: 0 (0.00%)\n",
      "# reads that failed to align: 49964939 (100.00%)\n",
      "No alignments\n",
      "\n",
      "bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 --un ^resuts/alignments/tRNA/ks68_nomatch.fastq --max ^resuts/alignments/tRNA/ks68_multi.fastq --al ^resuts/alignments/tRNA/ks68_match.fastq ^index/MG1655/Ec_tRNA ^resuts/alignments/ladder/ks68_nomatch.fastq ^resuts/tmpds/ks68_tRNA_match.SAM 1>> ^fastq/log_bowtie.txt 2>> ^fastq/log_bowtie.txt\n",
      "# reads processed: 49964939\n",
      "# reads with at least one reported alignment: 48985 (0.10%)\n",
      "# reads that failed to align: 49800627 (99.67%)\n",
      "# reads with alignments suppressed due to -m: 115327 (0.23%)\n",
      "Reported 48985 alignments to 1 output stream(s)\n",
      "\n",
      "bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 --un ^resuts/alignments/rRNA/ks68_nomatch.fastq --max ^resuts/alignments/rRNA/ks68_multi.fastq --al ^resuts/alignments/rRNA/ks68_match.fastq ^index/MG1655/rRNA_MG1655 ^resuts/alignments/tRNA/ks68_nomatch.fastq ^resuts/tmpds/ks68_rRNA_match.SAM 1>> ^fastq/log_bowtie.txt 2>> ^fastq/log_bowtie.txt\n",
      "# reads processed: 49800627\n",
      "# reads with at least one reported alignment: 17896 (0.04%)\n",
      "# reads that failed to align: 49522987 (99.44%)\n",
      "# reads with alignments suppressed due to -m: 259744 (0.52%)\n",
      "Reported 17896 alignments to 1 output stream(s)\n",
      "\n",
      "bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 --un ^resuts/alignments/ssrAssrS/ks68_nomatch.fastq --max ^resuts/alignments/ssrAssrS/ks68_multi.fastq --al ^resuts/alignments/ssrAssrS/ks68_match.fastq ^index/ssrAssrS/Ec_ssrA_ssrS ^resuts/alignments/rRNA/ks68_nomatch.fastq ^resuts/tmpds/ks68_ssrAssrS_match.SAM 1>> ^fastq/log_bowtie.txt 2>> ^fastq/log_bowtie.txt\n",
      "# reads processed: 49522987\n",
      "# reads with at least one reported alignment: 3487336 (7.04%)\n",
      "# reads that failed to align: 46035651 (92.96%)\n",
      "Reported 3487336 alignments to 1 output stream(s)\n",
      "\n",
      "bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 --un ^resuts/alignments/chr/ks68_nomatch.fastq --max ^resuts/alignments/chr/ks68_multi.fastq --al ^resuts/alignments/chr/ks68_match.fastq ^index/MG1655/e_coli_MG1655 ^resuts/alignments/ssrAssrS/ks68_nomatch.fastq ^resuts/alignments/chr/ks68_match.SAM 1>> ^fastq/log_bowtie.txt 2>> ^fastq/log_bowtie.txt\n",
      "# reads processed: 46035651\n",
      "# reads with at least one reported alignment: 44311226 (96.25%)\n",
      "# reads that failed to align: 910240 (1.98%)\n",
      "# reads with alignments suppressed due to -m: 814185 (1.77%)\n",
      "Reported 44311226 alignments to 1 output stream(s)\n",
      "\n",
      "2019-08-01 12:18:46.710687\n"
     ]
    }
   ],
   "source": [
    "log_file = bowtie_logfile\n",
    "###\n",
    "present = str(datetime.now())\n",
    "if not os.path.isfile(log_file):\n",
    "    logs = open(log_file, 'w')\n",
    "    logs.write(present+'\\n')\n",
    "    logs.close()\n",
    "else:\n",
    "    logs = open(log_file, 'a')\n",
    "    logs.write('\\n'+present+'\\n')\n",
    "    logs.close()    \n",
    "###\n",
    "\n",
    "path_l = outpath + 'alignments/ladder/'\n",
    "path_t = outpath + 'alignments/tRNA/'\n",
    "path_r = outpath + 'alignments/rRNA/'\n",
    "path_s = outpath + 'alignments/ssrAssrS/'\n",
    "path_chr = outpath + 'alignments/chr/'\n",
    "path_temp = outpath + 'tmpds/'\n",
    "\n",
    "if not os.path.exists(path_l):\n",
    "    os.makedirs(path_l)\n",
    "if not os.path.exists(path_t):\n",
    "    os.makedirs(path_t)\n",
    "if not os.path.exists(path_r):\n",
    "    os.makedirs(path_r)\n",
    "if not os.path.exists(path_s):\n",
    "    os.makedirs(path_s)\n",
    "if not os.path.exists(path_chr):\n",
    "    os.makedirs(path_chr)\n",
    "if not os.path.exists(path_temp):\n",
    "    os.makedirs(path_temp)\n",
    "\n",
    "for fname in files:\n",
    "    bowtie_command = 'bowtie -v 2 -y -m 1 -a --best --strata -S -p 30 '\\\n",
    "        '--un %s%s --max %s%s --al %s%s %s %s%s %s%s 1>> %s 2>> %s'\n",
    "        \n",
    "        # first, align to ladder index to subtract any ladder oligos that were cloned        \n",
    "    bowtie_ladder = bowtie_command %(\n",
    "        path_l,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_l,\n",
    "        fname+'_multi.fastq',\n",
    "        path_l,\n",
    "        fname+'_match.fastq',\n",
    "        '^index/ladder/ladder',\n",
    "        inpath,\n",
    "        fname + bowtie_input_extension,\n",
    "        path_temp,\n",
    "        fname + '_ladder_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "    ###\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n\\n'+fname+'\\n'+bowtie_ladder+'\\n')\n",
    "    logs.close()\n",
    "    ###\n",
    "    os.system(bowtie_ladder)        \n",
    "        \n",
    "        \n",
    "        # second, align to tRNA index\n",
    "    bowtie_tRNA = bowtie_command %(\n",
    "        path_t,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_t,\n",
    "        fname+'_multi.fastq',\n",
    "        path_t,\n",
    "        fname+'_match.fastq',\n",
    "        '^index/MG1655/Ec_tRNA',\n",
    "        path_l,\n",
    "        fname +'_nomatch.fastq',\n",
    "        path_temp,\n",
    "        fname + '_tRNA_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "    ###\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n'+bowtie_tRNA+'\\n')\n",
    "    logs.close()\n",
    "    ###\n",
    "    os.system(bowtie_tRNA)        \n",
    "        \n",
    "        \n",
    "        # third, align to the rRNA index\n",
    "    bowtie_rRNA = bowtie_command %(\n",
    "        path_r,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_r,\n",
    "        fname+'_multi.fastq',\n",
    "        path_r,\n",
    "        fname+'_match.fastq',\n",
    "        '^index/MG1655/rRNA_MG1655',\n",
    "        path_t,\n",
    "        fname +'_nomatch.fastq',\n",
    "        path_temp,\n",
    "        fname + '_rRNA_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "    ###\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n'+bowtie_rRNA+'\\n')\n",
    "    logs.close()\n",
    "    ###\n",
    "    os.system(bowtie_rRNA)         \n",
    "        \n",
    "        \n",
    "        # forth, align to the ssrA_ssrS index\n",
    "    bowtie_ssrAssrS = bowtie_command %(\n",
    "        path_s,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_s,\n",
    "        fname+'_multi.fastq',\n",
    "        path_s,\n",
    "        fname+'_match.fastq',\n",
    "        '^index/ssrAssrS/Ec_ssrA_ssrS',\n",
    "        path_r,\n",
    "        fname +'_nomatch.fastq',\n",
    "        path_temp,\n",
    "        fname + '_ssrAssrS_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "    ###\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n'+bowtie_ssrAssrS+'\\n')\n",
    "    logs.close()\n",
    "    ###\n",
    "    os.system(bowtie_ssrAssrS)\n",
    "        \n",
    "        \n",
    "        # finally align to the chr index\n",
    "    bowtie_chr = bowtie_command %(\n",
    "        path_chr,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_chr,\n",
    "        fname+'_multi.fastq',\n",
    "        path_chr,\n",
    "        fname+'_match.fastq',\n",
    "        '^index/MG1655/e_coli_MG1655',\n",
    "        path_s,\n",
    "        fname +'_nomatch.fastq',\n",
    "        path_chr,\n",
    "        fname + '_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "    ###\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n'+bowtie_chr+'\\n')\n",
    "    logs.close()\n",
    "    ###\n",
    "    os.system(bowtie_chr)\n",
    "    \n",
    "\n",
    "logs = open(log_file, 'a+')\n",
    "present = str(datetime.now())\n",
    "logs.write('\\n'+present+'\\n')\n",
    "logs.close()\n",
    "    \n",
    "print \n",
    "print \n",
    "for line in open(log_file, 'r'):\n",
    "    print line[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def five_end_mapping_opposite(samgen,GFFgen_filename):\n",
    "    from BCBio import GFF\n",
    "    from Bio import Seq\n",
    "    outputdata1={}\n",
    "    outputdata2={}\n",
    "    GFFgen=GFF.parse(GFFgen_filename)\n",
    "    for sequence in GFFgen:\n",
    "        outputdata1[sequence.id]=[0 for x in range(len(sequence))]\n",
    "        outputdata2[sequence.id]=[0 for x in range(len(sequence))]\n",
    "        for read in samgen:\n",
    "            if read[0][0] == '@':   # Ignore header lines.\n",
    "                continue\n",
    "            if read[1] == '4':      # A bowtie mismatch. These are the same as those previously saved in the files bowtie output as reads without matches and reads exceeding the -m limit. No need to write as fastq.\n",
    "                continue            \n",
    "            chrom = read[2]             # chromosome identified for read in bowtie\n",
    "            readid = read[0]            # read id\n",
    "            startp = int(read[3]) - 1    # start position. Need to subtract 1 since genomic sequence starts at 1, but list structures for read summing start at 0.\n",
    "            seq = Seq.Seq(read[9])      # sequence of the read\n",
    "            length = len(seq)           # length of read\n",
    "            if (read[1] == '16'):\n",
    "                start = startp + length - 1\n",
    "                outputdata1[chrom][start] += 1 ##### this is \"outputdata2\" for normal three_end_mapping\n",
    "            if (read[1] == '0'):\n",
    "                start = startp\n",
    "                outputdata2[chrom][start] += 1# #### this is \"outputdata2\" for normal three_end_mapping\n",
    "    return [outputdata1,outputdata2]  \n",
    "\n",
    "def readcounts_to_rpm(readcounts):\n",
    "    for chrom in readcounts.keys():\n",
    "        totalread = sum(readcounts[chrom])\n",
    "        for position in range(len(readcounts[chrom])):\n",
    "            readcounts[chrom][position]/=float(totalread)\n",
    "            readcounts[chrom][position]*=1E6\n",
    "\n",
    "# makes density file \n",
    "# the last letter \"f\" in writecountsf means float\n",
    "def writecountsf(rpm,filepath):  #Resultlist it is the list of counts, filestring is the file prefix for each chr to be written.\n",
    "    import struct\n",
    "    f2=open(filepath+\"keys\",\"w\")\n",
    "    for chrom in rpm.keys():\n",
    "        f=open(filepath+\"genome\",\"wb\")\n",
    "        # used to be (filepath+chrom,\"wb\") but server fail to show a file with a name containing \"|\"\n",
    "        # rename \"genome\" to real genome name manually \n",
    "        for position in rpm[chrom]:\n",
    "            f.write(struct.pack(\"f\",position))\n",
    "            # struct.pack to make binary based on the format indicated \n",
    "            # here, the indication of format is \"f\", which means float\n",
    "        f.close()\n",
    "        f2.write(chrom+\"\\n\")\n",
    "    f2.close()\n",
    "\n",
    "# makes wig file\n",
    "def countstowig(rpm,filestring):\n",
    "    import random\n",
    "    f=open(filestring+\".wig\",\"w\")\n",
    "    filestring=filestring.partition(\"_\")[0][-3:]\n",
    "\n",
    "    random.seed(filestring)\n",
    "    c1=random.randint(0,255)\n",
    "    random.seed(filestring+\"xxx\")\n",
    "    c2=random.randint(0,255)\n",
    "    random.seed(filestring+\"000\")\n",
    "    c3=random.randint(0,255)\n",
    "\n",
    "    f.write(\"track name=tracklabel viewLimits=-5:5 color=\"+str(c1)+','+str(c2)+','+str(c3)+\"\\n\")\n",
    "    for chrom in rpm.keys():\n",
    "        if chrom[0:3]=='chr':\n",
    "            f.write(\"fixedStep  chrom=\"+chrom+\"  start=1  step=1\\n\")\n",
    "        else:\n",
    "            f.write(\"fixedStep  chrom=\\\"\"+chrom+\"\\\"  start=1  step=1\\n\")\t# Note the extra '' around chrom added for E coli. Should be fine for yeast. Actually it's not. So new code here to detect that.\n",
    "\n",
    "\n",
    "        for position in rpm[chrom]:\n",
    "            f.write(str(position)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "import csv\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "out_path=filepath+'density/'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for f in files:\n",
    "    samgenmain_filename=filepath+'alignments/chr/'+f+'_match.SAM'\n",
    "    f_samgenmain=open(samgenmain_filename)\n",
    "    samgenmain=csv.reader(f_samgenmain,delimiter='\\t')\n",
    "\n",
    "    gff = 'coli.gff'\n",
    "\n",
    "    three_mapped=five_end_mapping_opposite(samgenmain,gff)\n",
    "    pickle_readcounts = out_path+f+mapping+'_readcounts.pickle'\n",
    "    with open(pickle_readcounts, 'wb') as readcounts_f:\n",
    "        pickle.dump(three_mapped,readcounts_f)\n",
    "\n",
    "    three_mapped_rpm = deepcopy(three_mapped)\n",
    "    readcounts_to_rpm(three_mapped_rpm[0])\n",
    "    readcounts_to_rpm(three_mapped_rpm[1])\n",
    "    pickle_rpm = out_path+f+mapping+'_rpm.pickle'\n",
    "    with open(pickle_rpm, 'wb') as rpm_f:\n",
    "        pickle.dump(three_mapped_rpm,rpm_f)\n",
    "        \n",
    "    density_path = out_path+f+mapping\n",
    "    writecountsf(three_mapped_rpm[0],density_path+\"_plus_\")\n",
    "    countstowig(three_mapped_rpm[0],density_path+\"_plus\")\n",
    "    writecountsf(three_mapped_rpm[1],density_path+\"_minus_\")\n",
    "    countstowig(three_mapped_rpm[1],density_path+\"_minus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a python-dictionary of RPKMs from each library\n",
    "import os\n",
    "import pickle\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "in_path = filepath+'density/'\n",
    "out_path = filepath+'expression/'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "with open('Ecoli_Gene_TU.pickle','rb') as GT_f:\n",
    "    Gene_TU_dict = pickle.load(GT_f)\n",
    "\n",
    "for f in files:\n",
    "    expression_dict={}\n",
    "    out_pickle=out_path+f+mapping+gene_type+'_expression.pickle'\n",
    "    out_csv=out_path+f+mapping+gene_type+'_expression.csv'\n",
    "    readcounts_file = in_path+f+mapping+'_readcounts.pickle'\n",
    "    \n",
    "    with open(readcounts_file, 'rb') as rf:\n",
    "        readcounts_dict = pickle.load(rf)\n",
    "    plus_readcounts = readcounts_dict[0][readcounts_dict[0].keys()[0]]\n",
    "    minus_readcounts = readcounts_dict[1][readcounts_dict[1].keys()[0]]\n",
    "    total_read = sum(plus_readcounts)+sum(minus_readcounts)\n",
    "    \n",
    "    for key in Gene_TU_dict.keys():\n",
    "        if key in expression_dict.keys():\n",
    "            print key +' is overlapping!!!'\n",
    "            continue\n",
    "        start = int(Gene_TU_dict[key][2])-1\n",
    "        end = int(Gene_TU_dict[key][3])\n",
    "        length = end-start\n",
    "        if length < 0:\n",
    "            print key + 'is shorter than zero!!!'\n",
    "            continue\n",
    "        if Gene_TU_dict[key][0] == '+':\n",
    "            reads = float(sum(plus_readcounts[start:end]))\n",
    "        if Gene_TU_dict[key][0] == '-':\n",
    "            reads = float(sum(minus_readcounts[start:end]))\n",
    "        rpc = (reads/length)*3\n",
    "        rpkm = (((reads/total_read)*1000000)/length)*1000\n",
    "        expression_dict[key]=[]\n",
    "        expression_dict[key].append(reads)\n",
    "        expression_dict[key].append(rpc)\n",
    "        expression_dict[key].append(rpkm)\n",
    "    \n",
    "    with open(out_pickle, 'wb') as op:\n",
    "        pickle.dump(expression_dict,op)           \n",
    "    \n",
    "    rpkm_DataFrame = DataFrame.from_dict(expression_dict, orient='index')\n",
    "    rpkm_DataFrame.columns = ['reads','rpc','rpkm']\n",
    "    rpkm_DataFrame.to_csv(out_csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
